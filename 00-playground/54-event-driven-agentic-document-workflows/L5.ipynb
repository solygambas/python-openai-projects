{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5b5ff6a-45fb-4cfa-a875-b5dbfe61b4b5",
   "metadata": {},
   "source": [
    "# Lesson 5: Human in the Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aac9f2-6cc8-4133-b8f4-40f3c81e7a67",
   "metadata": {},
   "source": [
    "**Lesson objective**: Get feedback on answers from a human operator\n",
    "\n",
    "In this lab, youâ€™ll learn how to make Workflows easy to iterate on answers to the questionnaire by getting feedback on answers from the human operator and re-answering when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e54f338",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff1d7; padding:15px;\"> <b> Note</b>: Make sure to run the notebook cell by cell. Please try to avoid running all cells at once.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dffa58e-3474-4c4f-8590-2479dae67252",
   "metadata": {
    "height": 385
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context\n",
    ")\n",
    "from helper import get_openai_api_key, get_llama_cloud_api_key\n",
    "from IPython.display import display, HTML\n",
    "from helper import extract_html_content\n",
    "from llama_index.utils.workflow import draw_all_possible_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de39fa29-12ac-4b3e-9d1e-94852b096839",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54946a4f-5ab5-4519-a0fe-ecf54268476b",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "llama_cloud_api_key = get_llama_cloud_api_key()\n",
    "openai_api_key = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b9eb70",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> ðŸ’» &nbsp; <b>To access <code>fake_application_form.pdf</code>, <code>fake_resume.pdf</code>, <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. The form and resume are inside the data folder.\n",
    "\n",
    "<p> â¬‡ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> ðŸ“’ &nbsp; For more help, please see the <em>\"Appendix â€“ Tips and Help\"</em> Lesson.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ed76b8",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d56f7-de48-4e1f-a288-a4c51db27251",
   "metadata": {},
   "source": [
    "## Adding a feedback loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2251da79-e354-4dba-8d49-67fa7278a11d",
   "metadata": {},
   "source": [
    "Here's what you built in lesson 4:\n",
    "\n",
    "<img width=\"400\" src=\"images/L4.png\">\n",
    "\n",
    "LLMs are amazing, but they are best used to augment rather than replace a human. Your current form-filler does an excellent job figuring out what fields need to be filled in, and gets most of the fields right, but there are a couple where it needs a little help. To take care of those, you'll create a \"human in the loop\" workflow, where you can optionally provide feedback to the agent you've created and have it incorporated into the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0b6dd6-9476-4b72-a7a5-9aa3ac2f2d5b",
   "metadata": {},
   "source": [
    "This is what you'll implement in this notebook:\n",
    "\n",
    "<img width=\"500\" src=\"images/L5.png\">\n",
    "\n",
    "The changes you're going to make here are:\n",
    "1. Use the `InputRequiredEvent` and `HumanResponseEvent`, new special events specifically designed to allow you to exit the workflow, and get feedback back into it.\n",
    "2. You used to have a single step which parsed your form and fired off all your questions. Since we now might loop back and ask questions several times, we don't need to parse the form every time, so we'll split up those steps. This kind of refactoring is very common as you create a more complex workflow:\n",
    "   - Your new `generate_questions` step will be triggered either by a `GenerateQuestionsEvent`, triggered by the form parser, or by a `FeedbackEvent`, which is the loop we'll take after getting feedback.\n",
    "3. `fill_in_application` will emit an `InputRequiredEvent`, and in the `external_step` you'll wait for a `HumanResponseEvent`. This will pause the whole workflow waiting for outside input.\n",
    "4. Finally, you'll use the LLM to parse the feedback and decide whether it means you should continue and output the results, or if you need to loop back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c6a7149-ded2-48b0-be39-eb32a9a22cca",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "# new!\n",
    "from llama_index.core.workflow import InputRequiredEvent, HumanResponseEvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c7ef5a-0a39-41a9-adc1-8785c7f644ee",
   "metadata": {
    "height": 285
   },
   "outputs": [],
   "source": [
    "class ParseFormEvent(Event):\n",
    "    application_form: str\n",
    "\n",
    "class QueryEvent(Event):\n",
    "    query: str\n",
    "    field: str\n",
    "    \n",
    "class ResponseEvent(Event):\n",
    "    response: str\n",
    "\n",
    "# new!\n",
    "class FeedbackEvent(Event):\n",
    "    feedback: str\n",
    "\n",
    "class GenerateQuestionsEvent(Event):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fd98cd7-1b98-4d26-976e-d2f9d1cea668",
   "metadata": {
    "height": 2527
   },
   "outputs": [],
   "source": [
    "class RAGWorkflow(Workflow):\n",
    "    \n",
    "    storage_dir = \"./storage\"\n",
    "    llm: OpenAI\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "\n",
    "        # define the LLM to work with\n",
    "        self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "        # ingest the data and set up the query engine\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            # you've already ingested the resume document\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=\n",
    "                                                           self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            # parse and load the resume document\n",
    "            documents = LlamaParse(\n",
    "                api_key=llama_cloud_api_key,\n",
    "                base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "                result_type=\"markdown\",\n",
    "                content_guideline_instruction=\"This is a resume, gather related facts together and format it as bullet points with headers\"\n",
    "            ).load_data(ev.resume_file)\n",
    "            # embed and index the documents\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        # create a query engine\n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        # you no longer need a query to be passed in, \n",
    "        # you'll be generating the queries instead \n",
    "        # let's pass the application form to a new step to parse it\n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "\n",
    "    # new - separated the form parsing from the question generation\n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> GenerateQuestionsEvent:\n",
    "        parser = LlamaParse(\n",
    "            api_key=llama_cloud_api_key,\n",
    "            base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "            result_type=\"markdown\",\n",
    "            content_guideline_instruction=\"This is a job application form. Create a list of all the fields that need to be filled in.\",\n",
    "            formatting_instruction=\"Return a bulleted list of the fields ONLY.\"\n",
    "        )\n",
    "\n",
    "        # get the LLM to convert the parsed form into JSON\n",
    "        result = parser.load_data(ev.application_form)[0]\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"This is a parsed form. Convert it into a JSON object containing only the list of fields to be filled in, in the form {{ fields: [...] }}. <form>{result.text}</form>. Return JSON ONLY, no markdown.\")\n",
    "        fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "        await ctx.set(\"fields_to_fill\", fields)\n",
    "\n",
    "        return GenerateQuestionsEvent()\n",
    "\n",
    "    # new - this step can get triggered either by GenerateQuestionsEvent or a FeedbackEvent\n",
    "    @step\n",
    "    async def generate_questions(self, ctx: Context, ev: GenerateQuestionsEvent | FeedbackEvent) -> QueryEvent:\n",
    "\n",
    "        # get the list of fields to fill in\n",
    "        fields = await ctx.get(\"fields_to_fill\")\n",
    "\n",
    "        # generate one query for each of the fields, and fire them off\n",
    "        for field in fields:\n",
    "            question = f\"How would you answer this question about the candidate? <field>{field}</field>\"\n",
    "            ctx.send_event(QueryEvent(\n",
    "                field=field,\n",
    "                query=question\n",
    "            ))\n",
    "\n",
    "        # store the number of fields so we know how many to wait for later\n",
    "        await ctx.set(\"total_fields\", len(fields))\n",
    "        return\n",
    "        \n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> ResponseEvent:\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "        return ResponseEvent(field=ev.field, response=response.response)\n",
    "\n",
    "  \n",
    "    # new - we now emit an InputRequiredEvent\n",
    "    @step\n",
    "    async def fill_in_application(self, ctx: Context, ev: ResponseEvent) -> InputRequiredEvent:\n",
    "        # get the total number of fields to wait for\n",
    "        total_fields = await ctx.get(\"total_fields\")\n",
    "\n",
    "        responses = ctx.collect_events(ev, [ResponseEvent] * total_fields)\n",
    "        if responses is None:\n",
    "            return None # do nothing if there's nothing to do yet\n",
    "\n",
    "        # we've got all the responses!\n",
    "        responseList = \"\\n\".join(\"Field: \" + r.field + \"\\n\" + \"Response: \" + r.response for r in responses)\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You are given a list of fields in an application form and responses to\n",
    "            questions about those fields from a resume. Combine the two into a list of\n",
    "            fields and succinct, factual answers to fill in those fields.\n",
    "\n",
    "            <responses>\n",
    "            {responseList}\n",
    "            </responses>\n",
    "        \"\"\")\n",
    "\n",
    "        # new! save the result for later\n",
    "        await ctx.set(\"filled_form\", str(result))\n",
    "\n",
    "        # new! Let's get a human in the loop\n",
    "        return InputRequiredEvent(\n",
    "            prefix=\"How does this look? Give me any feedback you have on any of the answers.\",\n",
    "            result=result\n",
    "        )\n",
    "\n",
    "    # new! Accept the feedback.\n",
    "    @step\n",
    "    async def get_feedback(self, ctx: Context, ev: HumanResponseEvent) -> FeedbackEvent | StopEvent:\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You have received some human feedback on the form-filling task you've done.\n",
    "            Does everything look good, or is there more work to be done?\n",
    "            <feedback>\n",
    "            {ev.response}\n",
    "            </feedback>\n",
    "            If everything is fine, respond with just the word 'OKAY'.\n",
    "            If there's any other feedback, respond with just the word 'FEEDBACK'.\n",
    "        \"\"\")\n",
    "\n",
    "        verdict = result.text.strip()\n",
    "\n",
    "        print(f\"LLM says the verdict was {verdict}\")\n",
    "        if (verdict == \"OKAY\"):\n",
    "            return StopEvent(result=await ctx.get(\"filled_form\"))\n",
    "        else:\n",
    "            return FeedbackEvent(feedback=ev.response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1112a0-32c6-4db7-933e-c03ff649cd8b",
   "metadata": {},
   "source": [
    "Okay! Your workflow is now ready to get some feedback, but how do we actually get it? The `InputRequiredEvent` is an event in the event stream, just like the `ProgressEvents` and `TextEvents` you've seen in lesson 2. You can intercept it the same way you did those, and use the `send_event` method on the context to send back a `HumanResponseEvent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a5cce3c-dde1-43ac-b52d-a0a4c3239210",
   "metadata": {
    "height": 385
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id ac1c826d-7e0e-4405-90e7-067f30f92169\n",
      "We've filled in your form! Here are the results:\n",
      "\n",
      "Here is the combined list of fields and succinct, factual answers based on the provided responses:\n",
      "\n",
      "1. **First Name**: Sarah\n",
      "2. **Last Name**: Chen\n",
      "3. **Email**: sarah.chen@email.com\n",
      "4. **Phone**: Not provided\n",
      "5. **LinkedIn**: linkedin.com/in/sarahchen\n",
      "6. **Project Portfolio**: Includes notable projects such as EcoTrack, a full-stack application for tracking carbon footprint, recognized in TechCrunch's \"Top 10 Environmental Impact Apps of 2023,\" and ChatFlow, a real-time chat application serving over 5000 monthly active users.\n",
      "7. **Degree**: Bachelor of Science in Computer Science\n",
      "8. **Graduation Date**: May 2017\n",
      "9. **Current Job Title**: Senior Full Stack Developer\n",
      "10. **Current Employer**: TechFlow Solutions\n",
      "11. **Technical Skills**: Proficient in frontend technologies (React.js, Redux, Next.js, TypeScript, Vue.js, HTML5, CSS3, SASS/SCSS) and backend technologies (Node.js, Express.js, Python, Django, API development with GraphQL and REST, PostgreSQL, MongoDB).\n",
      "12. **Describe why youâ€™re a good fit for this position**: Over 6 years of experience as a Full Stack Web Developer, proven track record in leading technical teams, architecting scalable web applications, and a solid foundation in both frontend and backend technologies. Committed to clean code and accessibility, with certifications in cloud architecture and experience with CI/CD pipelines.\n",
      "13. **Do you have 5 years of experience in React?**: Yes, over 6 years of experience in Full Stack Web Development, with specific expertise in React.\n",
      "How does this look? Give me any feedback you have on any of the answers.Project Portfolio should be a URL\n",
      "LLM says the verdict was FEEDBACK\n",
      "We've filled in your form! Here are the results:\n",
      "\n",
      "Here is the combined list of fields and succinct, factual answers based on the provided responses:\n",
      "\n",
      "1. **First Name**: Sarah\n",
      "2. **Last Name**: Chen\n",
      "3. **Email**: sarah.chen@email.com\n",
      "4. **Phone**: Not provided\n",
      "5. **LinkedIn**: linkedin.com/in/sarahchen\n",
      "6. **Project Portfolio**: Includes notable projects such as EcoTrack, a full-stack application for tracking carbon footprint, recognized in TechCrunch's \"Top 10 Environmental Impact Apps of 2023,\" and ChatFlow, a real-time chat application serving over 5000 monthly active users.\n",
      "7. **Degree**: Bachelor of Science in Computer Science\n",
      "8. **Graduation Date**: May 2017\n",
      "9. **Current Job Title**: Senior Full Stack Developer\n",
      "10. **Current Employer**: TechFlow Solutions\n",
      "11. **Technical Skills**: Proficient in frontend technologies (React.js, Redux, Next.js, TypeScript, Vue.js, HTML5, CSS3, SASS/SCSS) and backend technologies (Node.js, Express.js, Python, Django, API development with GraphQL and REST, PostgreSQL, MongoDB).\n",
      "12. **Describe why youâ€™re a good fit for this position**: Over 6 years of experience as a Full Stack Web Developer, proven track record in leading technical teams, architecting scalable web applications, and a solid foundation in both frontend and backend technologies. Committed to clean code and accessibility, with certifications in cloud architecture and experience with CI/CD pipelines.\n",
      "13. **Do you have 5 years of experience in React?**: Yes, over 6 years of experience in Full Stack Web Development, with specific expertise in React.\n",
      "How does this look? Give me any feedback you have on any of the answers.this is fine\n",
      "LLM says the verdict was OKAY\n",
      "Agent complete! Here's your final result:\n",
      "Here is the combined list of fields and succinct, factual answers based on the provided responses:\n",
      "\n",
      "1. **First Name**: Sarah\n",
      "2. **Last Name**: Chen\n",
      "3. **Email**: sarah.chen@email.com\n",
      "4. **Phone**: Not provided\n",
      "5. **LinkedIn**: linkedin.com/in/sarahchen\n",
      "6. **Project Portfolio**: Includes notable projects such as EcoTrack, a full-stack application for tracking carbon footprint, recognized in TechCrunch's \"Top 10 Environmental Impact Apps of 2023,\" and ChatFlow, a real-time chat application serving over 5000 monthly active users.\n",
      "7. **Degree**: Bachelor of Science in Computer Science\n",
      "8. **Graduation Date**: May 2017\n",
      "9. **Current Job Title**: Senior Full Stack Developer\n",
      "10. **Current Employer**: TechFlow Solutions\n",
      "11. **Technical Skills**: Proficient in frontend technologies (React.js, Redux, Next.js, TypeScript, Vue.js, HTML5, CSS3, SASS/SCSS) and backend technologies (Node.js, Express.js, Python, Django, API development with GraphQL and REST, PostgreSQL, MongoDB).\n",
      "12. **Describe why youâ€™re a good fit for this position**: Over 6 years of experience as a Full Stack Web Developer, proven track record in leading technical teams, architecting scalable web applications, and a solid foundation in both frontend and backend technologies. Committed to clean code and accessibility, with certifications in cloud architecture and experience with CI/CD pipelines.\n",
      "13. **Do you have 5 years of experience in React?**: Yes, over 6 years of experience in Full Stack Web Development, with specific expertise in React.\n"
     ]
    }
   ],
   "source": [
    "w = RAGWorkflow(timeout=600, verbose=False)\n",
    "handler = w.run(\n",
    "    resume_file=\"data/fake_resume.pdf\",\n",
    "    application_form=\"data/fake_application_form.pdf\"\n",
    ")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, InputRequiredEvent):\n",
    "        print(\"We've filled in your form! Here are the results:\\n\")\n",
    "        print(event.result)\n",
    "        # now ask for input from the keyboard\n",
    "        response = input(event.prefix)\n",
    "        handler.ctx.send_event(\n",
    "            HumanResponseEvent(\n",
    "                response=response\n",
    "            )\n",
    "        )\n",
    "\n",
    "response = await handler\n",
    "print(\"Agent complete! Here's your final result:\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da01c5-050a-4319-b9dc-39e55cc4bd7e",
   "metadata": {},
   "source": [
    "## Using the Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d6cf5f-148e-472e-9526-dac9a21364c8",
   "metadata": {},
   "source": [
    "Okay! Now let's further modify things to actually do something useful with the feedback in `generate_questions` step. This involves checking if there's feedback, and appending it to the questions. In this simple example, we're going to append the feedback to every question in case it's relevant, but a more sophisticated agent might apply it only to the fields where the feedback applied.\n",
    "\n",
    "<img width=\"500\" src=\"images/L5-use_feedback.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "081d90a7-95a6-4b02-914b-6aa09accb0c5",
   "metadata": {
    "height": 2646
   },
   "outputs": [],
   "source": [
    "class RAGWorkflow(Workflow):\n",
    "    \n",
    "    storage_dir = \"./storage\"\n",
    "    llm: OpenAI\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "\n",
    "        # define the LLM to work with\n",
    "        self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "        # ingest the data and set up the query engine\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            # you've already ingested the resume document\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=\n",
    "                                                           self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            # parse and load the resume document\n",
    "            documents = LlamaParse(\n",
    "                api_key=llama_cloud_api_key,\n",
    "                base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "                result_type=\"markdown\",\n",
    "                content_guideline_instruction=\"This is a resume, gather related facts together and format it as bullet points with headers\"\n",
    "            ).load_data(ev.resume_file)\n",
    "            # embed and index the documents\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        # create a query engine\n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        # let's pass the application form to a new step to parse it\n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "\n",
    "    # form parsing\n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> GenerateQuestionsEvent:\n",
    "        parser = LlamaParse(\n",
    "            api_key=llama_cloud_api_key,\n",
    "            base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "            result_type=\"markdown\",\n",
    "            content_guideline_instruction=\"This is a job application form. Create a list of all the fields that need to be filled in.\",\n",
    "            formatting_instruction=\"Return a bulleted list of the fields ONLY.\"\n",
    "        )\n",
    "\n",
    "        # get the LLM to convert the parsed form into JSON\n",
    "        result = parser.load_data(ev.application_form)[0]\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"This is a parsed form. Convert it into a JSON object containing only the list of fields to be filled in, in the form {{ fields: [...] }}. <form>{result.text}</form>. Return JSON ONLY, no markdown.\")\n",
    "        fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "        await ctx.set(\"fields_to_fill\", fields)\n",
    "\n",
    "        return GenerateQuestionsEvent()\n",
    "\n",
    "    # generate questions\n",
    "    @step\n",
    "    async def generate_questions(self, ctx: Context, ev: GenerateQuestionsEvent | FeedbackEvent) -> QueryEvent:\n",
    "\n",
    "        # get the list of fields to fill in\n",
    "        fields = await ctx.get(\"fields_to_fill\")\n",
    "\n",
    "        # generate one query for each of the fields, and fire them off\n",
    "        for field in fields:\n",
    "            question = f\"How would you answer this question about the candidate? <field>{field}</field>\"\n",
    "\n",
    "            # new! Is there feedback? If so, add it to the query:\n",
    "            if hasattr(ev,\"feedback\"):\n",
    "                question += f\"\"\"\n",
    "                    \\nWe previously got feedback about how we answered the questions.\n",
    "                    It might not be relevant to this particular field, but here it is:\n",
    "                    <feedback>{ev.feedback}</feedback>\n",
    "                \"\"\"\n",
    "            \n",
    "            ctx.send_event(QueryEvent(\n",
    "                field=field,\n",
    "                query=question\n",
    "            ))\n",
    "\n",
    "        # store the number of fields so we know how many to wait for later\n",
    "        await ctx.set(\"total_fields\", len(fields))\n",
    "        return\n",
    "        \n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> ResponseEvent:\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "        return ResponseEvent(field=ev.field, response=response.response)\n",
    "\n",
    "  \n",
    "    # Get feedback from the human\n",
    "    @step\n",
    "    async def fill_in_application(self, ctx: Context, ev: ResponseEvent) -> InputRequiredEvent:\n",
    "        # get the total number of fields to wait for\n",
    "        total_fields = await ctx.get(\"total_fields\")\n",
    "\n",
    "        responses = ctx.collect_events(ev, [ResponseEvent] * total_fields)\n",
    "        if responses is None:\n",
    "            return None # do nothing if there's nothing to do yet\n",
    "\n",
    "        # we've got all the responses!\n",
    "        responseList = \"\\n\".join(\"Field: \" + r.field + \"\\n\" + \"Response: \" + r.response for r in responses)\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You are given a list of fields in an application form and responses to\n",
    "            questions about those fields from a resume. Combine the two into a list of\n",
    "            fields and succinct, factual answers to fill in those fields.\n",
    "\n",
    "            <responses>\n",
    "            {responseList}\n",
    "            </responses>\n",
    "        \"\"\")\n",
    "\n",
    "        # save the result for later\n",
    "        await ctx.set(\"filled_form\", str(result))\n",
    "\n",
    "        # Fire off the feedback request\n",
    "        return InputRequiredEvent(\n",
    "            prefix=\"How does this look? Give me any feedback you have on any of the answers.\",\n",
    "            result=result\n",
    "        )\n",
    "\n",
    "    # Accept the feedback when a HumanResponseEvent fires\n",
    "    @step\n",
    "    async def get_feedback(self, ctx: Context, ev: HumanResponseEvent) -> FeedbackEvent | StopEvent:\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You have received some human feedback on the form-filling task you've done.\n",
    "            Does everything look good, or is there more work to be done?\n",
    "            <feedback>\n",
    "            {ev.response}\n",
    "            </feedback>\n",
    "            If everything is fine, respond with just the word 'OKAY'.\n",
    "            If there's any other feedback, respond with just the word 'FEEDBACK'.\n",
    "        \"\"\")\n",
    "\n",
    "        verdict = result.text.strip()\n",
    "\n",
    "        print(f\"LLM says the verdict was {verdict}\")\n",
    "        if (verdict == \"OKAY\"):\n",
    "            return StopEvent(result=await ctx.get(\"filled_form\"))\n",
    "        else:\n",
    "            return FeedbackEvent(feedback=ev.response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9230bc38-40cb-43d2-80ad-b179b96c2b82",
   "metadata": {},
   "source": [
    "Now run the workflow and give feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27001072-04b8-4459-b61b-f7cc0a441b37",
   "metadata": {
    "height": 385
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 45fb7113-4c8b-4a96-ab4a-257b766d83a8\n",
      "We've filled in your form! Here are the results:\n",
      "\n",
      "Here is the combined list of fields and succinct, factual answers based on the provided responses:\n",
      "\n",
      "1. **First Name**: Sarah\n",
      "2. **Last Name**: Chen\n",
      "3. **Email**: sarah.chen@email.com\n",
      "4. **Phone**: Not provided\n",
      "5. **LinkedIn**: linkedin.com/in/sarahchen\n",
      "6. **Project Portfolio**: Includes notable projects such as EcoTrack, a full-stack application for tracking carbon footprint, recognized in TechCrunch's \"Top 10 Environmental Impact Apps of 2023,\" and ChatFlow, a real-time chat application serving over 5000 monthly active users.\n",
      "7. **Degree**: Bachelor of Science in Computer Science\n",
      "8. **Graduation Date**: May 2017\n",
      "9. **Current Job Title**: Senior Full Stack Developer\n",
      "10. **Current Employer**: TechFlow Solutions\n",
      "11. **Technical Skills**: Proficient in frontend technologies (React.js, Redux, Next.js, TypeScript, Vue.js, HTML5, CSS3, SASS/SCSS) and backend technologies (Node.js, Express.js, Python, Django, API development with GraphQL and REST, PostgreSQL, MongoDB).\n",
      "12. **Describe why youâ€™re a good fit for this position**: Over 6 years of experience as a Full Stack Web Developer, proven track record in leading technical teams, architecting scalable web applications, and a solid foundation in both frontend and backend technologies. Committed to clean code and accessibility, with certifications in cloud architecture and experience with CI/CD pipelines.\n",
      "13. **Do you have 5 years of experience in React?**: Yes, over 6 years of experience in Full Stack Web Development, with specific expertise in React.\n",
      "How does this look? Give me any feedback you have on any of the answers.Project Portfolio should be a URL\n",
      "LLM says the verdict was FEEDBACK\n",
      "We've filled in your form! Here are the results:\n",
      "\n",
      "Here is the combined list of fields and succinct, factual answers:\n",
      "\n",
      "1. **First Name**: Sarah\n",
      "2. **Last Name**: Chen\n",
      "3. **Email**: sarah.chen@email.com\n",
      "4. **Phone**: Not provided\n",
      "5. **LinkedIn**: linkedin.com/in/sarahchen\n",
      "6. **Project Portfolio**: [sarahchen.dev](http://sarahchen.dev)\n",
      "7. **Degree**: Bachelor of Science in Computer Science from the University of California, Berkeley\n",
      "8. **Graduation Date**: May 2017\n",
      "9. **Current Job Title**: Senior Full Stack Developer\n",
      "10. **Current Employer**: TechFlow Solutions, San Francisco, CA\n",
      "11. **Technical Skills**: Proficient in frontend technologies (React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, HTML5, CSS3, SASS/SCSS) and backend technologies (Node.js, Express.js, Python, Django). Experienced with GraphQL, REST APIs, PostgreSQL, and MongoDB. Familiar with testing frameworks (Jest, React Testing Library) and build tools (WebPack, Babel).\n",
      "12. **Describe why youâ€™re a good fit for this position**: Over 6 years of experience as a Full Stack Web Developer, with leadership in technical teams and implementation of scalable web applications. Proficient in modern technologies (React, Node.js, cloud architecture), committed to clean code and accessibility, with a track record of improving code quality and reducing deployment times. Passionate about mentoring junior developers.\n",
      "13. **Do you have 5 years of experience in React?**: Yes, over 6 years of experience as a Full Stack Web Developer, including extensive work with React.\n",
      "How does this look? Give me any feedback you have on any of the answers.that's great\n",
      "LLM says the verdict was OKAY\n",
      "Agent complete! Here's your final result:\n",
      "Here is the combined list of fields and succinct, factual answers:\n",
      "\n",
      "1. **First Name**: Sarah\n",
      "2. **Last Name**: Chen\n",
      "3. **Email**: sarah.chen@email.com\n",
      "4. **Phone**: Not provided\n",
      "5. **LinkedIn**: linkedin.com/in/sarahchen\n",
      "6. **Project Portfolio**: [sarahchen.dev](http://sarahchen.dev)\n",
      "7. **Degree**: Bachelor of Science in Computer Science from the University of California, Berkeley\n",
      "8. **Graduation Date**: May 2017\n",
      "9. **Current Job Title**: Senior Full Stack Developer\n",
      "10. **Current Employer**: TechFlow Solutions, San Francisco, CA\n",
      "11. **Technical Skills**: Proficient in frontend technologies (React.js, Redux, Next.js, TypeScript, Vue.js, Nuxt.js, HTML5, CSS3, SASS/SCSS) and backend technologies (Node.js, Express.js, Python, Django). Experienced with GraphQL, REST APIs, PostgreSQL, and MongoDB. Familiar with testing frameworks (Jest, React Testing Library) and build tools (WebPack, Babel).\n",
      "12. **Describe why youâ€™re a good fit for this position**: Over 6 years of experience as a Full Stack Web Developer, with leadership in technical teams and implementation of scalable web applications. Proficient in modern technologies (React, Node.js, cloud architecture), committed to clean code and accessibility, with a track record of improving code quality and reducing deployment times. Passionate about mentoring junior developers.\n",
      "13. **Do you have 5 years of experience in React?**: Yes, over 6 years of experience as a Full Stack Web Developer, including extensive work with React.\n"
     ]
    }
   ],
   "source": [
    "w = RAGWorkflow(timeout=600, verbose=False)\n",
    "handler = w.run(\n",
    "    resume_file=\"data/fake_resume.pdf\",\n",
    "    application_form=\"data/fake_application_form.pdf\"\n",
    ")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, InputRequiredEvent):\n",
    "        print(\"We've filled in your form! Here are the results:\\n\")\n",
    "        print(event.result)\n",
    "        # now ask for input from the keyboard\n",
    "        response = input(event.prefix)\n",
    "        handler.ctx.send_event(\n",
    "            HumanResponseEvent(\n",
    "                response=response\n",
    "            )\n",
    "        )\n",
    "\n",
    "response = await handler\n",
    "print(\"Agent complete! Here's your final result:\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa46b976",
   "metadata": {},
   "source": [
    "## Workflow Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dfe9e8-9aed-4977-a5fc-07976b5e17a8",
   "metadata": {},
   "source": [
    "You can visualize the workflow you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9526d28-a1e9-43fe-baed-706a3c3adbc2",
   "metadata": {
    "height": 96
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n",
      "<class '__main__.ResponseEvent'>\n",
      "<class 'llama_index.core.workflow.events.InputRequiredEvent'>\n",
      "<class '__main__.QueryEvent'>\n",
      "<class '__main__.FeedbackEvent'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "<class '__main__.GenerateQuestionsEvent'>\n",
      "<class '__main__.ParseFormEvent'>\n",
      "workflows/feedback_workflow.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <div style=\"width: 100%; height: 800px; overflow: hidden;\"> <html>\n",
       "    <head>\n",
       "        <meta charset=\"utf-8\">\n",
       "        \n",
       "            <script src=\"lib/bindings/utils.js\"></script>\n",
       "            <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css\" integrity=\"sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\" />\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js\" integrity=\"sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n",
       "            \n",
       "        \n",
       "<center>\n",
       "<h1></h1>\n",
       "</center>\n",
       "\n",
       "<!-- <link rel=\"stylesheet\" href=\"../node_modules/vis/dist/vis.min.css\" type=\"text/css\" />\n",
       "<script type=\"text/javascript\" src=\"../node_modules/vis/dist/vis.js\"> </script>-->\n",
       "        <link\n",
       "          href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css\"\n",
       "          rel=\"stylesheet\"\n",
       "          integrity=\"sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        />\n",
       "        <script\n",
       "          src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js\"\n",
       "          integrity=\"sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        ></script>\n",
       "\n",
       "\n",
       "        <center>\n",
       "          <h1></h1>\n",
       "        </center>\n",
       "        <style type=\"text/css\">\n",
       "\n",
       "             #mynetwork {\n",
       "                 width: 100%;\n",
       "                 height: 750px;\n",
       "                 background-color: #ffffff;\n",
       "                 border: 1px solid lightgray;\n",
       "                 position: relative;\n",
       "                 float: left;\n",
       "             }\n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "        </style>\n",
       "    </head>\n",
       "\n",
       "\n",
       "    <body>\n",
       "        <div class=\"card\" style=\"width: 100%\">\n",
       "            \n",
       "            \n",
       "            <div id=\"mynetwork\" class=\"card-body\"></div>\n",
       "        </div>\n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        <script type=\"text/javascript\">\n",
       "\n",
       "              // initialize global variables.\n",
       "              var edges;\n",
       "              var nodes;\n",
       "              var allNodes;\n",
       "              var allEdges;\n",
       "              var nodeColors;\n",
       "              var originalNodes;\n",
       "              var network;\n",
       "              var container;\n",
       "              var options, data;\n",
       "              var filter = {\n",
       "                  item : '',\n",
       "                  property : '',\n",
       "                  value : []\n",
       "              };\n",
       "\n",
       "              \n",
       "\n",
       "              \n",
       "\n",
       "              // This method is responsible for drawing the graph, returns the drawn network\n",
       "              function drawGraph() {\n",
       "                  var container = document.getElementById('mynetwork');\n",
       "\n",
       "                  \n",
       "\n",
       "                  // parsing and collecting nodes and edges from the python\n",
       "                  nodes = new vis.DataSet([{\"color\": \"#FFA07A\", \"id\": \"StopEvent\", \"label\": \"StopEvent\", \"shape\": \"ellipse\"}, {\"color\": \"#ADD8E6\", \"id\": \"_done\", \"label\": \"_done\", \"shape\": \"box\"}, {\"color\": \"#ADD8E6\", \"id\": \"ask_question\", \"label\": \"ask_question\", \"shape\": \"box\"}, {\"color\": \"#90EE90\", \"id\": \"QueryEvent\", \"label\": \"QueryEvent\", \"shape\": \"ellipse\"}, {\"color\": \"#ADD8E6\", \"id\": \"fill_in_application\", \"label\": \"fill_in_application\", \"shape\": \"box\"}, {\"color\": \"#90EE90\", \"id\": \"ResponseEvent\", \"label\": \"ResponseEvent\", \"shape\": \"ellipse\"}, {\"color\": \"#90EE90\", \"id\": \"InputRequiredEvent\", \"label\": \"InputRequiredEvent\", \"shape\": \"ellipse\"}, {\"color\": \"#BEDAE4\", \"id\": \"external_step\", \"label\": \"external_step\", \"shape\": \"box\"}, {\"color\": \"#ADD8E6\", \"id\": \"generate_questions\", \"label\": \"generate_questions\", \"shape\": \"box\"}, {\"color\": \"#90EE90\", \"id\": \"GenerateQuestionsEvent\", \"label\": \"GenerateQuestionsEvent\", \"shape\": \"ellipse\"}, {\"color\": \"#90EE90\", \"id\": \"FeedbackEvent\", \"label\": \"FeedbackEvent\", \"shape\": \"ellipse\"}, {\"color\": \"#ADD8E6\", \"id\": \"get_feedback\", \"label\": \"get_feedback\", \"shape\": \"box\"}, {\"color\": \"#90EE90\", \"id\": \"HumanResponseEvent\", \"label\": \"HumanResponseEvent\", \"shape\": \"ellipse\"}, {\"color\": \"#ADD8E6\", \"id\": \"parse_form\", \"label\": \"parse_form\", \"shape\": \"box\"}, {\"color\": \"#90EE90\", \"id\": \"ParseFormEvent\", \"label\": \"ParseFormEvent\", \"shape\": \"ellipse\"}, {\"color\": \"#ADD8E6\", \"id\": \"set_up\", \"label\": \"set_up\", \"shape\": \"box\"}, {\"color\": \"#E27AFF\", \"id\": \"StartEvent\", \"label\": \"StartEvent\", \"shape\": \"ellipse\"}]);\n",
       "                  edges = new vis.DataSet([{\"arrows\": \"to\", \"from\": \"StopEvent\", \"to\": \"_done\"}, {\"arrows\": \"to\", \"from\": \"ask_question\", \"to\": \"ResponseEvent\"}, {\"arrows\": \"to\", \"from\": \"QueryEvent\", \"to\": \"ask_question\"}, {\"arrows\": \"to\", \"from\": \"fill_in_application\", \"to\": \"InputRequiredEvent\"}, {\"arrows\": \"to\", \"from\": \"InputRequiredEvent\", \"to\": \"external_step\"}, {\"arrows\": \"to\", \"from\": \"ResponseEvent\", \"to\": \"fill_in_application\"}, {\"arrows\": \"to\", \"from\": \"generate_questions\", \"to\": \"QueryEvent\"}, {\"arrows\": \"to\", \"from\": \"GenerateQuestionsEvent\", \"to\": \"generate_questions\"}, {\"arrows\": \"to\", \"from\": \"FeedbackEvent\", \"to\": \"generate_questions\"}, {\"arrows\": \"to\", \"from\": \"get_feedback\", \"to\": \"FeedbackEvent\"}, {\"arrows\": \"to\", \"from\": \"get_feedback\", \"to\": \"StopEvent\"}, {\"arrows\": \"to\", \"from\": \"HumanResponseEvent\", \"to\": \"get_feedback\"}, {\"arrows\": \"to\", \"from\": \"external_step\", \"to\": \"HumanResponseEvent\"}, {\"arrows\": \"to\", \"from\": \"parse_form\", \"to\": \"GenerateQuestionsEvent\"}, {\"arrows\": \"to\", \"from\": \"ParseFormEvent\", \"to\": \"parse_form\"}, {\"arrows\": \"to\", \"from\": \"set_up\", \"to\": \"ParseFormEvent\"}, {\"arrows\": \"to\", \"from\": \"StartEvent\", \"to\": \"set_up\"}]);\n",
       "\n",
       "                  nodeColors = {};\n",
       "                  allNodes = nodes.get({ returnType: \"Object\" });\n",
       "                  for (nodeId in allNodes) {\n",
       "                    nodeColors[nodeId] = allNodes[nodeId].color;\n",
       "                  }\n",
       "                  allEdges = edges.get({ returnType: \"Object\" });\n",
       "                  // adding nodes and edges to the graph\n",
       "                  data = {nodes: nodes, edges: edges};\n",
       "\n",
       "                  var options = {\n",
       "    \"configure\": {\n",
       "        \"enabled\": false\n",
       "    },\n",
       "    \"edges\": {\n",
       "        \"color\": {\n",
       "            \"inherit\": true\n",
       "        },\n",
       "        \"smooth\": {\n",
       "            \"enabled\": true,\n",
       "            \"type\": \"dynamic\"\n",
       "        }\n",
       "    },\n",
       "    \"interaction\": {\n",
       "        \"dragNodes\": true,\n",
       "        \"hideEdgesOnDrag\": false,\n",
       "        \"hideNodesOnDrag\": false\n",
       "    },\n",
       "    \"physics\": {\n",
       "        \"enabled\": true,\n",
       "        \"stabilization\": {\n",
       "            \"enabled\": true,\n",
       "            \"fit\": true,\n",
       "            \"iterations\": 1000,\n",
       "            \"onlyDynamicEdges\": false,\n",
       "            \"updateInterval\": 50\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  network = new vis.Network(container, data, options);\n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  return network;\n",
       "\n",
       "              }\n",
       "              drawGraph();\n",
       "        </script>\n",
       "    </body>\n",
       "</html> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "isolated": true
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "WORKFLOW_FILE = \"workflows/feedback_workflow.html\"\n",
    "draw_all_possible_flows(w, filename=WORKFLOW_FILE)\n",
    "html_content = extract_html_content(WORKFLOW_FILE)\n",
    "display(HTML(html_content), metadata=dict(isolated=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efde360-1bbd-48b7-8c70-0aa7745b24ec",
   "metadata": {},
   "source": [
    "## Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c843af32-46d9-410d-a21d-8c132a8a2421",
   "metadata": {},
   "source": [
    "The agent now responds to Human-in-the-loop feedback and produces more accurate filled forms as a result. Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
