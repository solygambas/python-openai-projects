{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcfda5ce-4f4a-4582-b4ae-ab309696eedf",
   "metadata": {},
   "source": [
    "# Lesson 5: Creating an MCP Client "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6211ebe3-496b-4f54-b811-1b778787ae8f",
   "metadata": {},
   "source": [
    "In the previous lesson, you created an MCP research server that exposes 2 tools. In this lesson, you will make the chatbot communicate to the server through an MCP client. This will make the chatbot MCP compatible. You will continue from where you left off in lesson 4, i.e., you are provided again with the `mcp_project` folder that contains the `research_server.py` file. You'll add to it the MCP chatbot file and update the environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc42aa-75b1-44b5-a3d4-d56f77b34cd9",
   "metadata": {},
   "source": [
    "<img src=\"images/lesson_progression.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de6333f",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> ðŸ’» &nbsp; <b> To Access the  <code>mcp_project</code> folder :</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em> and finally 3) click on <em>L5</em>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981dcfb4-b58c-4ed5-b63f-d6a1b03642d8",
   "metadata": {},
   "source": [
    "## Back to the Chatbot Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa381b7c-5203-4795-a726-bd7698deaf62",
   "metadata": {},
   "source": [
    "Here are the main code parts (`process_query`, `chat_loop`) from the chatbot example of lesson 3. Notice that the burden of tool definitions and execution is now shifted onto the MCP server, so the chatbot logic only contains code related to processing the user queries and to keeping the chat loop running until the user types `quit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a2e6fe7-a727-402b-bb6e-265bf2a580e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import anthropic\n",
    "\n",
    "load_dotenv()\n",
    "anthropic = anthropic.Anthropic()\n",
    "\n",
    "def process_query(query):\n",
    "    messages = [{'role':'user', 'content':query}]\n",
    "    response = anthropic.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-3-7-sonnet-20250219', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages)\n",
    "    process_query = True\n",
    "    while process_query:\n",
    "        assistant_content = []\n",
    "        for content in response.content:\n",
    "            if content.type =='text':\n",
    "                print(content.text)\n",
    "                assistant_content.append(content)\n",
    "                if(len(response.content)==1):\n",
    "                    process_query= False\n",
    "            elif content.type == 'tool_use':\n",
    "                assistant_content.append(content)\n",
    "                messages.append({'role':'assistant', 'content':assistant_content})\n",
    "                tool_id = content.id\n",
    "                tool_args = content.input\n",
    "                tool_name = content.name\n",
    "\n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "                # Call a tool\n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                messages.append({\"role\": \"user\", \n",
    "                                  \"content\": [\n",
    "                                      {\n",
    "                                          \"type\": \"tool_result\",\n",
    "                                          \"tool_use_id\":tool_id,\n",
    "                                          \"content\": result\n",
    "                                      }\n",
    "                                  ]\n",
    "                                })\n",
    "                response = anthropic.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-3-7-sonnet-20250219', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages) \n",
    "                \n",
    "                if(len(response.content)==1 and response.content[0].type == \"text\"):\n",
    "                    print(response.content[0].text)\n",
    "                    process_query= False\n",
    "\n",
    "\n",
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b764075a-1ca5-4820-8fdb-6c244a7a8324",
   "metadata": {},
   "source": [
    "## Building your MCP Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b159c4-e06e-4a0c-acb4-028e2046ed73",
   "metadata": {},
   "source": [
    "Now you will take the functions `process_query` and `chat_loop` and wrap them in a `MCP_ChatBot` class. To enable the chatbot to communicate to the server, you will add a method that connects to the server through an MCP client, which follows the structure given in this reference code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec2225f-f389-4fe6-85c7-6e96aa5bbb18",
   "metadata": {},
   "source": [
    "### Reference Code\n",
    "``` python\n",
    "from mcp import ClientSession, StdioServerParameters, types\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "# Create server parameters for stdio connection\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"uv\",  # Executable\n",
    "    args=[\"run example_server.py\"],  # Command line arguments\n",
    "    env=None,  # Optional environment variables\n",
    ")\n",
    "\n",
    "async def run():\n",
    "    # Launch the server as a subprocess & returns the read and write streams\n",
    "    # read: the stream that the client will use to read msgs from the server\n",
    "    # write: the stream that client will use to write msgs to the server\n",
    "    async with stdio_client(server_params) as (read, write): \n",
    "        # the client session is used to initiate the connection \n",
    "        # and send requests to server \n",
    "        async with ClientSession(read, write) as session:\n",
    "            # Initialize the connection (1:1 connection with the server)\n",
    "            await session.initialize()\n",
    "\n",
    "            # List available tools\n",
    "            tools = await session.list_tools()\n",
    "\n",
    "            # will call the chat_loop here\n",
    "            # ....\n",
    "            \n",
    "            # Call a tool: this will be in the process_query method\n",
    "            result = await session.call_tool(\"tool-name\", arguments={\"arg1\": \"value\"})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(run())\n",
    "`````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e380fcdc-1703-40a6-9dd0-600c6ba2bdb1",
   "metadata": {},
   "source": [
    "### Adding MCP Client to the Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b442185-9c23-47a2-8a7e-f92928a45bed",
   "metadata": {},
   "source": [
    "The MCP_ChatBot class consists of the methods:\n",
    "- `process_query`\n",
    "- `chat_loop`\n",
    "- `connect_to_server_and_run`\n",
    "  \n",
    "and has the following attributes:\n",
    "- session (of type ClientSession)\n",
    "- anthropic: Anthropic                           \n",
    "- available_tools\n",
    "\n",
    "In `connect_to_server_and_run`, the client launches the server and requests the list of tools that the server provides (through the client session). The tool definitions are stored in the variable `available_tools` and are passed in to the LLM in `process_query`.\n",
    "\n",
    "<img src=\"images/tools_discovery.png\" width=\"400\">\n",
    "\n",
    "\n",
    "In `process_query`, when the LLM decides it requires a tool to be executed, the client session sends to the server the tool call request. The returned response is passed in to the LLM. \n",
    "\n",
    "<img src=\"images/tool_invocation.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b96d918-1854-49b5-8930-f1a6962a3ee9",
   "metadata": {},
   "source": [
    "Here're the `mcp_chatbot` code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c305bb8-6474-420e-82b4-e6daecb65d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_project/mcp_chatbot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_project/mcp_chatbot.py\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "from mcp import ClientSession, StdioServerParameters, types\n",
    "from mcp.client.stdio import stdio_client\n",
    "from typing import List\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class MCP_ChatBot:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize session and client objects\n",
    "        self.session: ClientSession = None\n",
    "        self.anthropic = Anthropic()\n",
    "        self.available_tools: List[dict] = []\n",
    "\n",
    "    async def process_query(self, query):\n",
    "        messages = [{'role':'user', 'content':query}]\n",
    "        response = self.anthropic.messages.create(max_tokens = 2024,\n",
    "                                      model = 'claude-3-7-sonnet-20250219', \n",
    "                                      tools = self.available_tools, # tools exposed to the LLM\n",
    "                                      messages = messages)\n",
    "        process_query = True\n",
    "        while process_query:\n",
    "            assistant_content = []\n",
    "            for content in response.content:\n",
    "                if content.type =='text':\n",
    "                    print(content.text)\n",
    "                    assistant_content.append(content)\n",
    "                    if(len(response.content) == 1):\n",
    "                        process_query= False\n",
    "                elif content.type == 'tool_use':\n",
    "                    assistant_content.append(content)\n",
    "                    messages.append({'role':'assistant', 'content':assistant_content})\n",
    "                    tool_id = content.id\n",
    "                    tool_args = content.input\n",
    "                    tool_name = content.name\n",
    "    \n",
    "                    print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                    \n",
    "                    # Call a tool\n",
    "                    #result = execute_tool(tool_name, tool_args): not anymore needed\n",
    "                    # tool invocation through the client session\n",
    "                    result = await self.session.call_tool(tool_name, arguments=tool_args)\n",
    "                    messages.append({\"role\": \"user\", \n",
    "                                      \"content\": [\n",
    "                                          {\n",
    "                                              \"type\": \"tool_result\",\n",
    "                                              \"tool_use_id\":tool_id,\n",
    "                                              \"content\": result.content\n",
    "                                          }\n",
    "                                      ]\n",
    "                                    })\n",
    "                    response = self.anthropic.messages.create(max_tokens = 2024,\n",
    "                                      model = 'claude-3-7-sonnet-20250219', \n",
    "                                      tools = self.available_tools,\n",
    "                                      messages = messages) \n",
    "                    \n",
    "                    if(len(response.content) == 1 and response.content[0].type == \"text\"):\n",
    "                        print(response.content[0].text)\n",
    "                        process_query= False\n",
    "\n",
    "    \n",
    "    \n",
    "    async def chat_loop(self):\n",
    "        \"\"\"Run an interactive chat loop\"\"\"\n",
    "        print(\"\\nMCP Chatbot Started!\")\n",
    "        print(\"Type your queries or 'quit' to exit.\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                query = input(\"\\nQuery: \").strip()\n",
    "        \n",
    "                if query.lower() == 'quit':\n",
    "                    break\n",
    "                    \n",
    "                await self.process_query(query)\n",
    "                print(\"\\n\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"\\nError: {str(e)}\")\n",
    "    \n",
    "    async def connect_to_server_and_run(self):\n",
    "        # Create server parameters for stdio connection\n",
    "        server_params = StdioServerParameters(\n",
    "            command=\"uv\",  # Executable\n",
    "            args=[\"run\", \"research_server.py\"],  # Optional command line arguments\n",
    "            env=None,  # Optional environment variables\n",
    "        )\n",
    "        async with stdio_client(server_params) as (read, write):\n",
    "            async with ClientSession(read, write) as session:\n",
    "                self.session = session\n",
    "                # Initialize the connection\n",
    "                await session.initialize()\n",
    "    \n",
    "                # List available tools\n",
    "                response = await session.list_tools()\n",
    "                \n",
    "                tools = response.tools\n",
    "                print(\"\\nConnected to server with tools:\", [tool.name for tool in tools])\n",
    "                \n",
    "                self.available_tools = [{\n",
    "                    \"name\": tool.name,\n",
    "                    \"description\": tool.description,\n",
    "                    \"input_schema\": tool.inputSchema\n",
    "                } for tool in response.tools]\n",
    "    \n",
    "                await self.chat_loop()\n",
    "\n",
    "\n",
    "async def main():\n",
    "    chatbot = MCP_ChatBot()\n",
    "    await chatbot.connect_to_server_and_run()\n",
    "  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95df7af0-162a-4419-a188-12a2c6058ab2",
   "metadata": {},
   "source": [
    "## Running the MCP Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dca4737-0d67-4429-9379-8228b5c9ebf1",
   "metadata": {},
   "source": [
    "**Terminal Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48b00b-d256-47f0-8002-170ea74876c0",
   "metadata": {},
   "source": [
    "- To open the terminal, run the cell below.\n",
    "- Navigate to the `mcp_project` directory:\n",
    "    - `cd L5/mcp_project`\n",
    "- Activate the virtual environment:\n",
    "    - `source .venv/bin/activate`\n",
    "- Install the additional dependencies:\n",
    "    - `uv add anthropic python-dotenv nest_asyncio`\n",
    "- Run the chatbot:\n",
    "    - `uv run mcp_chatbot.py`\n",
    "- To exit the chatbot, type `quit`.\n",
    "- If you run some queries and would like to access the `papers` folder: 1) click on the `File` option on the top menu of the notebook and 2) click on `Open` and then 3) click on `L5` -> `mcp_project`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d511872f-9c1e-481a-a3b1-0069f3588981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"768\"\n",
       "            src=\"https://s172-29-67-160p8888.lab-aws-production.deeplearning.ai/terminals/2\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f39597f54d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new terminal\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(f\"{os.environ.get('DLAI_LOCAL_URL').format(port=8888)}terminals/2\", width=600, height=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d76196-52a5-4337-86b9-31878f558f99",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf205d7-aef2-4254-a29a-3a06911163b5",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d0517c-8571-4c64-88dd-358fab27ed13",
   "metadata": {},
   "source": [
    "- [Quick Start for Client Developpers](https://modelcontextprotocol.io/quickstart/client)\n",
    "- [Writing MCP client](https://github.com/modelcontextprotocol/python-sdk/blob/main/examples/clients/simple-chatbot/mcp_simple_chatbot/main.py)\n",
    "- [Another mcp chatbot example](https://github.com/modelcontextprotocol/python-sdk/blob/main/examples/clients/simple-chatbot/mcp_simple_chatbot/main.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f28922a-af5f-475e-a56a-ae5e77f94cf7",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> ðŸ’» &nbsp; <b> To Access the  <code>mcp_project</code> folder :</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em> and then 3) on \"L5\".\n",
    "<p> â¬‡ &nbsp; <b>To Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> ðŸ“’ &nbsp; For more help, please see the <em>\"Appendix â€“ Tips, Help, and Download\"</em> Lesson.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea0666a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
